{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "k-means.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6OnHkeKnAUAnlnVUyEsUv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LifeofAGeek/100-days-of-Applied-AI/blob/master/k_means.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqGmFPFU61Oc"
      },
      "source": [
        "#**K-means Clustering**\n",
        "Here I've implemented K-means clustering on few 2D points without using any library. Below are two methods of choosing initial clusters centroids which i'm going to study:\n",
        "\n",
        "\n",
        "1.   Randomly generate initial centroids within range for different attributes.\n",
        "2.   Randomly select K data objects within the dataset as initial centroids.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7GYf42Q-Zr6"
      },
      "source": [
        "\n",
        "\n",
        "# > **1. Randomly select K data objects within the dataset as initial centroids.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3nsiRXRanYo",
        "outputId": "cf9ff522-91f3-4d9b-9457-b6b3865047f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "#Euclidian Distance between two d-dimensional points\n",
        "def eucldist(p0,p1):\n",
        "    dist = 0.0\n",
        "    for i in range(0,len(p0)):\n",
        "        dist += (p0[i] - p1[i])**2\n",
        "    return math.sqrt(dist)\n",
        "\n",
        "\n",
        "    \n",
        "#K-Means Algorithm\n",
        "def kmeans(k,datapoints):\n",
        "\n",
        "    # d - Dimensionality of Datapoints\n",
        "    d = len(datapoints[0]) \n",
        "    \n",
        "    #Limit our iterations\n",
        "    Max_Iterations = 1000\n",
        "    i = 0\n",
        "    \n",
        "    cluster = [0] * len(datapoints)\n",
        "    prev_cluster = [-1] * len(datapoints)\n",
        "    \n",
        "    #Randomly Choose Centers for the Clusters\n",
        "    cluster_centers = []\n",
        "    print(\"k =\",k)\n",
        "    for i in range(0,k):\n",
        "        cluster_centers += [random.choice(datapoints)] #randomly choosen datapoints from dataset as initial centeroid \n",
        "        if(i==k-1):\n",
        "          print(\"Initial Choosen Centroids from the dataset: \",cluster_centers,\"\\n\")\n",
        "        \n",
        "        \n",
        "        #Sometimes The Random points are chosen poorly and so there ends up being empty clusters\n",
        "        #In this particular implementation we want to force K exact clusters.\n",
        "        #To take this feature off, simply take away \"force_recalculation\" from the while conditional.\n",
        "        force_recalculation = False\n",
        "    \n",
        "    while (cluster != prev_cluster) or (i > Max_Iterations) or (force_recalculation) :\n",
        "        \n",
        "        prev_cluster = list(cluster)\n",
        "        force_recalculation = False\n",
        "        i += 1\n",
        "    \n",
        "        #Update Point's Cluster Alligiance\n",
        "        for p in range(0,len(datapoints)):\n",
        "            min_dist = float(\"inf\")\n",
        "            \n",
        "            #Check min_distance against all centers\n",
        "            for c in range(0,len(cluster_centers)):\n",
        "                \n",
        "                dist = eucldist(datapoints[p],cluster_centers[c])\n",
        "                \n",
        "                if (dist < min_dist):\n",
        "                    min_dist = dist  \n",
        "                    cluster[p] = c   # Reassign Point to new Cluster\n",
        "        \n",
        "        \n",
        "        #Update Cluster's Position\n",
        "        for k in range(0,len(cluster_centers)):\n",
        "            new_center = [0] * d\n",
        "            members = 0\n",
        "            for p in range(0,len(datapoints)):\n",
        "                if (cluster[p] == k): #If this point belongs to the cluster\n",
        "                    for j in range(0,d):\n",
        "                        new_center[j] += datapoints[p][j]\n",
        "                    members += 1\n",
        "            \n",
        "            for j in range(0,d):\n",
        "                if members != 0:\n",
        "                    new_center[j] = new_center[j] / float(members) \n",
        "                \n",
        "                #This means that our initial random assignment was poorly chosen\n",
        "                #Change it to a new datapoint to actually force k clusters\n",
        "                else: \n",
        "                    new_center = random.choice(datapoints)\n",
        "                    force_recalculation = True\n",
        "                    print(\"Forced Recalculation...\")\n",
        "                    \n",
        "            \n",
        "            cluster_centers[k] = new_center\n",
        "    \n",
        "        \n",
        "    print(\"================================== Results ==================================\\n\")\n",
        "    print(\"Final Clusters after K-means Clustering: \", cluster_centers)\n",
        "    print(\"Total Iterations made: \",i)\n",
        "    print(\"Cluster label Assignments: \", cluster)\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #2D - Datapoints List of n d-dimensional vectors. (For this example I already set up 2D Tuples)\n",
        "    datapoints = [(3,2),(2,2),(1,2),(0,1),(1,0),(1,1),(5,6),(7,7),(9,10),(11,13),(12,12),(12,13),(13,13)]\n",
        "\n",
        "    k = 1 # K - Number of Clusters\n",
        "      \n",
        "    kmeans(k,datapoints)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 1\n",
            "Initial Choosen Centroids from the dataset:  [(13, 13)] \n",
            "\n",
            "================================== Results ==================================\n",
            "\n",
            "Final Clusters after K-means Clustering:  [[5.923076923076923, 6.3076923076923075]]\n",
            "Total Iterations made:  1\n",
            "Cluster label Assignments:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvOcMdFlEr1J"
      },
      "source": [
        "## **Results of above method for K={1,2,3,4,5}**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "k = 1\n",
        "Initial Choosen Centroids from the dataset:  [(13, 13)] \n",
        "\n",
        "================================== Results ==================================\n",
        "\n",
        "Final Clusters after K-means Clustering:  [[5.923076923076923, 6.3076923076923075]]\n",
        "Total Iterations made:  1\n",
        "Cluster label Assignments:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "k = 2\n",
        "Initial Choosen Centroids from the dataset:  [(0, 1), (13, 13)] \n",
        "\n",
        "================================== Results ==================================\n",
        "\n",
        "Final Clusters after K-means Clustering:  [[1.8571428571428572, 2.0], [10.666666666666666, 11.333333333333334]]\n",
        "Total Iterations made:  3\n",
        "Cluster label Assignments:  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "k = 3\n",
        "Initial Choosen Centroids from the dataset:  [(13, 13), (11, 13), (7, 7)] \n",
        "\n",
        "================================== Results ==================================\n",
        "\n",
        "Final Clusters after K-means Clustering:  [[12.0, 12.75], [7.0, 7.666666666666667], [1.3333333333333333, 1.3333333333333333]]\n",
        "Total Iterations made:  6\n",
        "Cluster label Assignments:  [2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "k = 4\n",
        "Initial Choosen Centroids from the dataset:  [(3, 2), (1, 0), (1, 1), (3, 2)] \n",
        "\n",
        "Forced Recalculation...\n",
        "Forced Recalculation...\n",
        "================================== Results ==================================\n",
        "\n",
        "Final Clusters after K-means Clustering:  [[7.0, 7.666666666666667], [0.6666666666666666, 0.6666666666666666], [2.0, 2.0], [12.0, 12.75]]\n",
        "Total Iterations made:  8\n",
        "Cluster label Assignments:  [2, 2, 2, 1, 1, 1, 0, 0, 0, 3, 3, 3, 3]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "k = 5\n",
        "Initial Choosen Centroids from the dataset:  [(7, 7), (9, 10), (12, 13), (1, 2), (3, 2)] \n",
        "\n",
        "================================== Results ==================================\n",
        "\n",
        "Final Clusters after K-means Clustering:  [[6.0, 6.5], [9.0, 10.0], [12.0, 12.75], [0.75, 1.0], [2.5, 2.0]]\n",
        "Total Iterations made:  7\n",
        "Cluster label Assignments:  [4, 4, 3, 3, 3, 3, 0, 0, 1, 2, 2, 2, 2]\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOFOdIsL96ms"
      },
      "source": [
        "\n",
        "\n",
        "# > **2. Randomly generate initial centroids within range for different attributes.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPe-0BQy-Hfb",
        "outputId": "f2ac22ef-e392-4105-d90a-a3f7be6ad9b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "#Euclidian Distance between two d-dimensional points\n",
        "def eucldist(p0,p1):\n",
        "    dist = 0.0\n",
        "    for i in range(0,len(p0)):\n",
        "        dist += (p0[i] - p1[i])**2\n",
        "    return math.sqrt(dist)\n",
        "\n",
        "\n",
        "    \n",
        "#K-Means Algorithm\n",
        "def kmeans(k,datapoints):\n",
        "\n",
        "    # d - Dimensionality of Datapoints\n",
        "    d = len(datapoints[0]) \n",
        "    \n",
        "    #Limit our iterations\n",
        "    Max_Iterations = 1000\n",
        "    i = 0\n",
        "    \n",
        "    cluster = [0] * len(datapoints)\n",
        "    prev_cluster = [-1] * len(datapoints)\n",
        "    \n",
        "    #Randomly Choose Centers for the Clusters\n",
        "    cluster_centers = []\n",
        "    print(\"k =\",k)\n",
        "    for i in range(0,k):\n",
        "        cluster_centers += [(random.randint(0, 15),random.randint(0, 15))] #randomly generated initial centroids in range of (0,15).\n",
        "        if(i==k-1):\n",
        "          print(\"Initial Choosen Centroids from the dataset: \",cluster_centers,\"\\n\")\n",
        "        \n",
        "        \n",
        "        #Sometimes The Random points are chosen poorly and so there ends up being empty clusters\n",
        "        #In this particular implementation we want to force K exact clusters.\n",
        "        #To take this feature off, simply take away \"force_recalculation\" from the while conditional.\n",
        "        force_recalculation = False\n",
        "    \n",
        "    while (cluster != prev_cluster) or (i > Max_Iterations) or (force_recalculation) :\n",
        "        \n",
        "        prev_cluster = list(cluster)\n",
        "        force_recalculation = False\n",
        "        i += 1\n",
        "    \n",
        "        #Update Point's Cluster Alligiance\n",
        "        for p in range(0,len(datapoints)):\n",
        "            min_dist = float(\"inf\")\n",
        "            \n",
        "            #Check min_distance against all centers\n",
        "            for c in range(0,len(cluster_centers)):\n",
        "                \n",
        "                dist = eucldist(datapoints[p],cluster_centers[c])\n",
        "                \n",
        "                if (dist < min_dist):\n",
        "                    min_dist = dist  \n",
        "                    cluster[p] = c   # Reassign Point to new Cluster\n",
        "        \n",
        "        \n",
        "        #Update Cluster's Position\n",
        "        for k in range(0,len(cluster_centers)):\n",
        "            new_center = [0] * d\n",
        "            members = 0\n",
        "            for p in range(0,len(datapoints)):\n",
        "                if (cluster[p] == k): #If this point belongs to the cluster\n",
        "                    for j in range(0,d):\n",
        "                        new_center[j] += datapoints[p][j]\n",
        "                    members += 1\n",
        "            \n",
        "            for j in range(0,d):\n",
        "                if members != 0:\n",
        "                    new_center[j] = new_center[j] / float(members) \n",
        "                \n",
        "                #This means that our initial random assignment was poorly chosen\n",
        "                #Change it to a new datapoint to actually force k clusters\n",
        "                else: \n",
        "                    new_center = random.choice(datapoints)\n",
        "                    force_recalculation = True\n",
        "                    print(\"Forced Recalculation...\")\n",
        "                    \n",
        "            \n",
        "            cluster_centers[k] = new_center\n",
        "    \n",
        "        \n",
        "    print(\"================================== Results ==================================\\n\")\n",
        "    print(\"Final Clusters after K-means Clustering: \", cluster_centers)\n",
        "    print(\"Total Iterations made: \",i)\n",
        "    print(\"Cluster label Assignments: \", cluster)\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #2D - Datapoints List of n d-dimensional vectors. (For this example I already set up 2D Tuples)\n",
        "    datapoints = [(3,2),(2,2),(1,2),(0,1),(1,0),(1,1),(5,6),(7,7),(9,10),(11,13),(12,12),(12,13),(13,13)]\n",
        "\n",
        "    k = 5 # K - Number of Clusters\n",
        "      \n",
        "    kmeans(k,datapoints)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 5\n",
            "Initial Choosen Centroids from the dataset:  [(13, 11), (0, 8), (8, 10), (1, 4), (7, 5)] \n",
            "\n",
            "Forced Recalculation...\n",
            "Forced Recalculation...\n",
            "================================== Results ==================================\n",
            "\n",
            "Final Clusters after K-means Clustering:  [[12.0, 12.75], [0.6666666666666666, 0.6666666666666666], [9.0, 10.0], [2.0, 2.0], [6.0, 6.5]]\n",
            "Total Iterations made:  9\n",
            "Cluster label Assignments:  [3, 3, 3, 1, 1, 1, 4, 4, 2, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38_ZnSS5FsrX"
      },
      "source": [
        "## **Results of above method for K={1,2,3,4,5}**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "k = 1\n",
        "Initial Choosen Centroids from the dataset:  [(1, 6)] \n",
        "\n",
        "================================== Results ==================================\n",
        "\n",
        "Final Clusters after K-means Clustering:  [[5.923076923076923, 6.3076923076923075]]\n",
        "Total Iterations made:  1\n",
        "Cluster label Assignments:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "k = 2\n",
        "Initial Choosen Centroids from the dataset:  [(14, 4), (13, 13)] \n",
        "\n",
        "================================== Results ==================================\n",
        "\n",
        "Final Clusters after K-means Clustering:  [[2.5, 2.625], [11.4, 12.2]]\n",
        "Total Iterations made:  3\n",
        "Cluster label Assignments:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "k = 3\n",
        "Initial Choosen Centroids from the dataset:  [(12, 9), (8, 12), (13, 6)] \n",
        "\n",
        "================================== Results ==================================\n",
        "\n",
        "Final Clusters after K-means Clustering:  [[11.4, 12.2], [6.0, 6.5], [1.3333333333333333, 1.3333333333333333]]\n",
        "Total Iterations made:  5\n",
        "Cluster label Assignments:  [2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0]\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "k = 4\n",
        "Initial Choosen Centroids from the dataset:  [(5, 9), (1, 8), (2, 6), (9, 2)] \n",
        "\n",
        "Forced Recalculation...\n",
        "Forced Recalculation...\n",
        "Forced Recalculation...\n",
        "Forced Recalculation...\n",
        "================================== Results ==================================\n",
        "\n",
        "Final Clusters after K-means Clustering:  [[8.0, 8.5], [5.0, 6.0], [1.3333333333333333, 1.3333333333333333], [12.0, 12.75]]\n",
        "Total Iterations made:  7\n",
        "Cluster label Assignments:  [2, 2, 2, 2, 2, 2, 1, 0, 0, 3, 3, 3, 3]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "k = 5\n",
        "Initial Choosen Centroids from the dataset:  [(13, 11), (0, 8), (8, 10), (1, 4), (7, 5)] \n",
        "\n",
        "Forced Recalculation...\n",
        "Forced Recalculation...\n",
        "================================== Results ==================================\n",
        "\n",
        "Final Clusters after K-means Clustering:  [[12.0, 12.75], [0.6666666666666666, 0.6666666666666666], [9.0, 10.0], [2.0, 2.0], [6.0, 6.5]]\n",
        "Total Iterations made:  9\n",
        "Cluster label Assignments:  [3, 3, 3, 1, 1, 1, 4, 4, 2, 0, 0, 0, 0]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYQ14W6FAoNB"
      },
      "source": [
        "# **Analysis and comparison between above two methods!**\n",
        "\n",
        "> As k-means clustering aims to converge on an optimal set of cluster centers (centroids) and cluster membership based on distance from these centroids via successive iterations, it is intuitive that the more optimal the positioning of these initial centroids, the fewer iterations of the k-means clustering algorithms will be required for convergence.\n",
        "\n",
        "> Both of the methods gave very similar results and which was pretty obvious because we can't see much difference in running time complexity in smaller dataset. Thus this method is highly volatile and provides for a scenario where the selected centroids are not well positioned throughout the entire data space.\n",
        "\n",
        "> It can be noticed that number of iterations made(say Time Complexity) to lablel all clusters will depend on the way we are choosing the initial clusters.\n",
        "\n",
        "> If we choose smarty our intial centers by sorting and bisecting of dataset into k regions and then taking their median rather than by randomly selecting initial centroids, we will land up having very few iteration.\n",
        "\n",
        "> Better Centroid Initialization Methods can be used such as k-means++, naive sharding, Ward's method for better results in terms of time complexity.\n",
        "\n",
        "\n"
      ]
    }
  ]
}